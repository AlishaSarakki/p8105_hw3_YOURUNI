Homework\_3
================

``` r
library(tidyverse)
```

    ## ── Attaching packages ─────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(dplyr)
library(ggplot2)
library(ggridges)
library(patchwork)
library(rnoaa)
```

    ## Registered S3 method overwritten by 'hoardr':
    ##   method           from
    ##   print.cache_info httr

``` r
install.packages("hexbin", repos ="http://cran.us.r-project.org")
```

    ## 
    ## The downloaded binary packages are in
    ##  /var/folders/0q/5mcr2xbn0752fbrxdrkmkdkh0000gn/T//RtmpiF7maU/downloaded_packages

``` r
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

``` r
# install.packages("devtools")
devtools::install_github("p8105/p8105.datasets")
```

    ## Skipping install of 'p8105.datasets' from a github remote, the SHA1 (412759e3) has not changed since last install.
    ##   Use `force = TRUE` to force installation

``` r
library(p8105.datasets)
data("instacart")  
```

This dataset contains 1384617 rows and …columns.

Observations are the level of items in orders by user. There are some
user/order variables – user ID, order ID, order day, and order hour.
There are also item variables – name, aisle, department, and some
numeric codes.

How many aisles, and which are most items from?

``` r
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

    ## # A tibble: 134 x 2
    ##    aisle                              n
    ##    <chr>                          <int>
    ##  1 fresh vegetables              150609
    ##  2 fresh fruits                  150473
    ##  3 packaged vegetables fruits     78493
    ##  4 yogurt                         55240
    ##  5 packaged cheese                41699
    ##  6 water seltzer sparkling water  36617
    ##  7 milk                           32644
    ##  8 chips pretzels                 31269
    ##  9 soy lactosefree                26240
    ## 10 bread                          23635
    ## # … with 124 more rows

let’s make a plot

``` r
instacart %>% 
   count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1))
```

<img src="p8105_hw3_aps2204_files/figure-gfm/unnamed-chunk-4-1.png" width="90%" />

Let’s make a table\!

``` r
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

Apples vs ice cream

``` r
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

    ## # A tibble: 2 x 8
    ## # Groups:   product_name [2]
    ##   product_name       `0`   `1`   `2`   `3`   `4`   `5`   `6`
    ##   <chr>            <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>
    ## 1 Coffee Ice Cream  13.8  14.3  15.4  15.3  15.2  12.3  13.8
    ## 2 Pink Lady Apples  13.4  11.4  11.7  14.2  11.6  12.8  11.9

## Problem 2

Import and tidy data

``` r
accel_data = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate_at(vars(activity_1:activity_1400), as.numeric) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute_of_day",
    values_to = "activity_count",
    names_prefix = "activity") %>% 
 mutate(weekday_end = case_when(
day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday") ~ "weekday",
day %in% c("Saturday","Sunday") ~ "weekend")) %>% 
  relocate("week", "weekday_end", "day", "day_id", "minute_of_day", "activity_count") %>% 
   mutate_at(vars("weekday_end","day"), as.factor) %>% 
  mutate_at(vars("day_id", "week", "activity_count"), as.double) %>% 
  mutate(
  day = forcats::fct_relevel(day, "Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")
  )
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

This data was collected over 5 weeks from a 63 year-old male diagnosed
with CHF. Variables in this dataset include week, weekday/end
(here,coded as weekday\_end), day (Sunday - Saturday), day of the month
(day\_id), and activity count. This dataset contains 50400 observations,
which were collected at each minute of the day, every day, for 5 weeks.

group by and summarize into table

``` r
agg_accel = 
accel_data %>% 
  group_by(day_id, day, week) %>% 
  summarize(activity = sum(activity_count)) 
```

    ## `summarise()` regrouping output by 'day_id', 'day' (override with `.groups` argument)

``` r
knitr::kable(agg_accel)
```

| day\_id | day       | week |  activity |
| ------: | :-------- | ---: | --------: |
|       1 | Friday    |    1 | 480542.62 |
|       2 | Monday    |    1 |  78828.07 |
|       3 | Saturday  |    1 | 376254.00 |
|       4 | Sunday    |    1 | 631105.00 |
|       5 | Thursday  |    1 | 355923.64 |
|       6 | Tuesday   |    1 | 307094.24 |
|       7 | Wednesday |    1 | 340115.01 |
|       8 | Friday    |    2 | 568839.00 |
|       9 | Monday    |    2 | 295431.00 |
|      10 | Saturday  |    2 | 607175.00 |
|      11 | Sunday    |    2 | 422018.00 |
|      12 | Thursday  |    2 | 474048.00 |
|      13 | Tuesday   |    2 | 423245.00 |
|      14 | Wednesday |    2 | 440962.00 |
|      15 | Friday    |    3 | 467420.00 |
|      16 | Monday    |    3 | 685910.00 |
|      17 | Saturday  |    3 | 382928.00 |
|      18 | Sunday    |    3 | 467052.00 |
|      19 | Thursday  |    3 | 371230.00 |
|      20 | Tuesday   |    3 | 381507.00 |
|      21 | Wednesday |    3 | 468869.00 |
|      22 | Friday    |    4 | 154049.00 |
|      23 | Monday    |    4 | 409450.00 |
|      24 | Saturday  |    4 |   1440.00 |
|      25 | Sunday    |    4 | 260617.00 |
|      26 | Thursday  |    4 | 340291.00 |
|      27 | Tuesday   |    4 | 319568.00 |
|      28 | Wednesday |    4 | 434460.00 |
|      29 | Friday    |    5 | 620860.00 |
|      30 | Monday    |    5 | 389080.00 |
|      31 | Saturday  |    5 |   1440.00 |
|      32 | Sunday    |    5 | 138421.00 |
|      33 | Thursday  |    5 | 549658.00 |
|      34 | Tuesday   |    5 | 367824.00 |
|      35 | Wednesday |    5 | 445366.00 |

Fridays tend to be a high activity day, while weekends seem to have
lower activity. Saturdays especially have a lower activity count. Weeks
1, 2, and 5 seem to have a high activity count, with the exception of
Saturday in Week 5. Week 4 seems to have a lower relative activity count
as compared to other weeks of the same month. An activity count of 1440
is repeated twice - this number may have some significance.

Single-panel plot

``` r
accel_data %>%
  ggplot(aes(x = minute_of_day, y = activity_count)) +
  geom_line(aes(), alpha = .3) +
  labs(
    title = "Activity Plotted Over 5-Week Period",
    x = "Minute of Day",
    y = "Activity Count",
    caption = "data from accelerometer dataset"
  ) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

<img src="p8105_hw3_aps2204_files/figure-gfm/single panel plot of accel_data-1.png" width="90%" />

``` r
# I was unable to figure out what is going on with my x-axis, and any code I created to adjust it resulted in my document being unable to knit. I was also unable to facet correctly - the code I wanted to include was face_grid(.~ month) at the very end. 
```

This data was difficult to interpret as it is very dense.

## Problem 3

Load and tidy data

``` r
library(p8105.datasets)
data("ny_noaa")

skimr::skim(ny_noaa)
```

|                                                  |          |
| :----------------------------------------------- | :------- |
| Name                                             | ny\_noaa |
| Number of rows                                   | 2595176  |
| Number of columns                                | 7        |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |          |
| Column type frequency:                           |          |
| character                                        | 3        |
| Date                                             | 1        |
| numeric                                          | 3        |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |          |
| Group variables                                  | None     |

Data summary

**Variable type: character**

| skim\_variable | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
| :------------- | ---------: | -------------: | --: | --: | ----: | --------: | ---------: |
| id             |          0 |           1.00 |  11 |  11 |     0 |       747 |          0 |
| tmax           |    1134358 |           0.56 |   1 |   4 |     0 |       532 |          0 |
| tmin           |    1134420 |           0.56 |   1 |   4 |     0 |       548 |          0 |

**Variable type: Date**

| skim\_variable | n\_missing | complete\_rate | min        | max        | median     | n\_unique |
| :------------- | ---------: | -------------: | :--------- | :--------- | :--------- | --------: |
| date           |          0 |              1 | 1981-01-01 | 2010-12-31 | 1997-01-21 |     10957 |

**Variable type: numeric**

| skim\_variable | n\_missing | complete\_rate |  mean |     sd |   p0 | p25 | p50 | p75 |  p100 | hist  |
| :------------- | ---------: | -------------: | ----: | -----: | ---: | --: | --: | --: | ----: | :---- |
| prcp           |     145838 |           0.94 | 29.82 |  78.18 |    0 |   0 |   0 |  23 | 22860 | ▇▁▁▁▁ |
| snow           |     381221 |           0.85 |  4.99 |  27.22 | \-13 |   0 |   0 |   0 | 10160 | ▇▁▁▁▁ |
| snwd           |     591786 |           0.77 | 37.31 | 113.54 |    0 |   0 |   0 |   0 |  9195 | ▇▁▁▁▁ |

This dataset from the National Oceanic and Atmospheric Association
describes the weather in New York from all NY weather stations between
January 1st, 1981 to December 31st, 2010. The data contains 2595176 rows
and 7 columns. Variables include station ID, date of data collection,
and measurements of precipitation, snow, snow depth, and maximum +
minimum temperatures per day. There is significant missing data,
especially as related to minimum and maximum temperatures - both tmin
and tmax have over 1 million missing values.

Clean data and create separate variables for year, month, day; adjust
variables to proper units and find mode

``` r
tidy_noaa = (
  ny_noaa %>% 
  separate(date, into = c("year", "month", "day"), convert = "TRUE") %>% 
  mutate(
  tmin = as.double(tmin),
  tmax = as.double(tmax)
) %>% 
  mutate(
  (tmin = (tmin/10)),
  (tmax = (tmax/10)),
  (prcp = (prcp/10))
  ))

skimr::skim(tidy_noaa)
```

|                                                  |            |
| :----------------------------------------------- | :--------- |
| Name                                             | tidy\_noaa |
| Number of rows                                   | 2595176    |
| Number of columns                                | 12         |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_   |            |
| Column type frequency:                           |            |
| character                                        | 1          |
| numeric                                          | 11         |
| \_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_ |            |
| Group variables                                  | None       |

Data summary

**Variable type: character**

| skim\_variable | n\_missing | complete\_rate | min | max | empty | n\_unique | whitespace |
| :------------- | ---------: | -------------: | --: | --: | ----: | --------: | ---------: |
| id             |          0 |              1 |  11 |  11 |     0 |       747 |          0 |

**Variable type: numeric**

| skim\_variable     | n\_missing | complete\_rate |    mean |     sd |      p0 |    p25 |    p50 |    p75 |  p100 | hist  |
| :----------------- | ---------: | -------------: | ------: | -----: | ------: | -----: | -----: | -----: | ----: | :---- |
| year               |          0 |           1.00 | 1996.50 |   9.19 |  1981.0 | 1988.0 | 1997.0 | 2005.0 |  2010 | ▆▆▅▅▇ |
| month              |          0 |           1.00 |    6.56 |   3.45 |     1.0 |    4.0 |    7.0 |   10.0 |    12 | ▇▅▅▅▇ |
| day                |          0 |           1.00 |   15.73 |   8.80 |     1.0 |    8.0 |   16.0 |   23.0 |    31 | ▇▇▇▇▆ |
| prcp               |     145838 |           0.94 |   29.82 |  78.18 |     0.0 |    0.0 |    0.0 |   23.0 | 22860 | ▇▁▁▁▁ |
| snow               |     381221 |           0.85 |    4.99 |  27.22 |  \-13.0 |    0.0 |    0.0 |    0.0 | 10160 | ▇▁▁▁▁ |
| snwd               |     591786 |           0.77 |   37.31 | 113.54 |     0.0 |    0.0 |    0.0 |    0.0 |  9195 | ▇▁▁▁▁ |
| tmax               |    1134358 |           0.56 |  139.80 | 111.42 | \-389.0 |   50.0 |  150.0 |  233.0 |   600 | ▁▂▇▆▁ |
| tmin               |    1134420 |           0.56 |   30.29 | 104.00 | \-594.0 | \-39.0 |   33.0 |  111.0 |   600 | ▁▁▇▂▁ |
| (tmin = (tmin/10)) |    1134420 |           0.56 |    3.03 |  10.40 |  \-59.4 |  \-3.9 |    3.3 |   11.1 |    60 | ▁▁▇▂▁ |
| (tmax = (tmax/10)) |    1134358 |           0.56 |   13.98 |  11.14 |  \-38.9 |    5.0 |   15.0 |   23.3 |    60 | ▁▂▇▆▁ |
| (prcp = (prcp/10)) |     145838 |           0.94 |    2.98 |   7.82 |     0.0 |    0.0 |    0.0 |    2.3 |  2286 | ▇▁▁▁▁ |

``` r
  tidy_noaa %>% 
  count(snow) %>% 
  arrange(snow)
```

    ## # A tibble: 282 x 2
    ##     snow       n
    ##    <int>   <int>
    ##  1   -13       1
    ##  2     0 2008508
    ##  3     3    8790
    ##  4     5    9748
    ##  5     8    9962
    ##  6    10    5106
    ##  7    13   23095
    ##  8    15    3672
    ##  9    18    3226
    ## 10    20    4797
    ## # … with 272 more rows

``` r
tidy_noaa
```

    ## # A tibble: 2,595,176 x 12
    ##    id     year month   day  prcp  snow  snwd  tmax  tmin `(tmin = (tmin/…
    ##    <chr> <int> <int> <int> <int> <int> <int> <dbl> <dbl>            <dbl>
    ##  1 US1N…  2007    11     1    NA    NA    NA    NA    NA               NA
    ##  2 US1N…  2007    11     2    NA    NA    NA    NA    NA               NA
    ##  3 US1N…  2007    11     3    NA    NA    NA    NA    NA               NA
    ##  4 US1N…  2007    11     4    NA    NA    NA    NA    NA               NA
    ##  5 US1N…  2007    11     5    NA    NA    NA    NA    NA               NA
    ##  6 US1N…  2007    11     6    NA    NA    NA    NA    NA               NA
    ##  7 US1N…  2007    11     7    NA    NA    NA    NA    NA               NA
    ##  8 US1N…  2007    11     8    NA    NA    NA    NA    NA               NA
    ##  9 US1N…  2007    11     9    NA    NA    NA    NA    NA               NA
    ## 10 US1N…  2007    11    10    NA    NA    NA    NA    NA               NA
    ## # … with 2,595,166 more rows, and 2 more variables: `(tmax = (tmax/10))` <dbl>,
    ## #   `(prcp = (prcp/10))` <dbl>

The most commonly observed value in this dataset is a snowfall amount of
0mm. This is likely because snow typically only falls within a narrow
timeframe of the year (select days in winter). As such, we would not
expect the most common value to be anything but 0mm.

Problem 3, part 2

``` r
  tidy_noaa %>% 
  mutate(month = as.character(month)) %>% 
  filter(month == c(1,7)) %>%
  group_by(id, year, month) %>% 
  summarize(mean_tmax = mean(tmax)) %>% 
  ggplot(aes(x = year, y = mean_tmax)) +
  geom_point(alpha = 0.5) +
  geom_smooth(se = FALSE) +
 facet_grid(. ~month) +
  labs(
    title = "Avg Max Temps in January and July from 1981 to 2010",
    x = "year",
    y = "mean maximum temperature (tenths of degrees C)",
    caption = "data from New York NOAA"
  )
```

    ## `summarise()` regrouping output by 'id', 'year' (override with `.groups` argument)

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

    ## Warning: Removed 6843 rows containing non-finite values (stat_smooth).

    ## Warning: Removed 6843 rows containing missing values (geom_point).

<img src="p8105_hw3_aps2204_files/figure-gfm/2-panel plot-1.png" width="90%" />

``` r
# I was unable to troubleshoot the temperature issue. I recognize that there is no place inhabitable by humans at 300 degrees celsius (that's a bit crispy), and I don't think that even Siberia gets to -100 degrees celsius. I apologize - something went wrong with my code, but I hope my legend titles corrected for that?). 
```

    Observations include: July has higher maximum temperatures, on average, than January. Temperatures seem to fluctuate in cycles. 1994, 2003, and 2004 appear to have been a particularly cold winters, though it is difficult to determine whether they are outliers. January temperatures seem to fluctuate more than those in July. July 1987 appears to be an outlier in that it was much colder than average July temperatures. 
    
    
    tmax vs. tmin
    
    ```r
    tmax_plot = (
    tidy_noaa %>% 
    ggplot(aes(x = tmin, y = tmax)) +
    geom_hex() +
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
     labs(
        title = "Tmax distribution",
        x = "tmin (tenths of degrees C)",
        y = "tmax (tenths of degrees C)",
        caption = "data from New York NOAA"
      ))

This figure compares maximum and minimum temperatures in a hexplot. Min
and max temperatures overlap between -150 to 150 tenths of a degree
celsius (-15 to 15 degrees C). The data shows several outliers, though a
majority is condensed between -50 and 50 degrees C.

snowfall distribution

``` r
snowfall_plot = (
tidy_noaa %>% 
filter(
snow > 0, 
snow < 100
) %>% 
group_by(year) %>% 
ggplot(aes(x = snow, y = snow)) +
geom_boxplot() + 
facet_wrap(.~ year) +
 labs(
    title = "Snowfall Distribution From 1981 to 2010",
    x = "year",
    y = "snowfall distribution(mm)",
    caption = "data from New York NOAA"
  ))
```

Snowfall distribution through the years shows fairly consistent results,
with the exception of some outliers in 2006 and 2010. The boxplots for
each year describe that year’s snowfall, while dots around the
“whiskers” represent outliers. Some years had more outliers than
others.

patchwork the plots\!

``` r
library(patchwork)
tmax_plot + snowfall_plot
```

    ## Warning: Removed 1136276 rows containing non-finite values (stat_binhex).

    ## Warning: Continuous x aesthetic -- did you forget aes(group=...)?

<img src="p8105_hw3_aps2204_files/figure-gfm/putting it together-1.png" width="90%" />
The combined plots allow for a side-by-side comparison of temperature
and snowfall. The left panel shows the average temperature maximum and
minimum distribution, while the right plot shows the average snowfall
distribution over the years. Data show that both measures (temperature
and snowfall) are centered around a median range, with several outliers
in certain years (this is especially apparent in the snowfall
distribution dataset).
