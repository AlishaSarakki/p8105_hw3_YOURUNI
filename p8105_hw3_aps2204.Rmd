---
title: "Homework_3"
output: github_document
---
```{r}
library(tidyverse)
library(dplyr)
library(ggplot2)
library(ggridges)
library(patchwork)
library(rnoaa)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


## Problem 1
```{r}
# install.packages("devtools")
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data("instacart")  
```

This dataset contains `r nrow(instacart)` rows and ...columns.

Observations are the level of items in orders by user. There are some user/order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes.

How many aisles, and which are most items from?

```{r}
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))

```

let's make a plot

```{r}
instacart %>% 
   count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(
    aisle = factor(aisle),
    aisle = fct_reorder(aisle, n)
  ) %>% 
  ggplot(aes(x = aisle, y = n)) +
  geom_point() +
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust = 1))
```


Let's make a table!

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(aisle, rank) %>% 
  knitr::kable()
```


Apples vs ice cream

```{r}
instacart %>% 
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
  group_by(product_name, order_dow) %>% 
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  )
```



## Problem 2

Import and tidy data
```{r import and tidy accel_data}
accel_data = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate_at(vars(activity_1:activity_1400), as.numeric) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute_of_day",
    values_to = "activity_count",
    names_prefix = "activity") %>% 
 mutate(weekday_end = case_when(
day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday") ~ "weekday",
day %in% c("Saturday","Sunday") ~ "weekend")) %>% 
  relocate("week", "weekday_end", "day", "day_id", "minute_of_day", "activity_count") %>% 
   mutate_at(vars("weekday_end","day"), as.factor) %>% 
  mutate_at(vars("day_id", "week", "activity_count"), as.double) %>% 
  mutate(
  day = forcats::fct_relevel(day, "Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday")
  )
  
  
```

This data was collected over 5 weeks from a 63 year-old male diagnosed with CHF. Variables in this dataset include week, weekday/end (here,coded as weekday_end), day (Sunday - Saturday), day of the month (day_id), and activity count. This dataset contains `r nrow(accel_data)` observations, which were collected at each minute of the day, every day, for 5 weeks.



group by and summarize into table
```{r accel_data table}
agg_accel = 
accel_data %>% 
  group_by(day_id, day, week) %>% 
  summarize(activity = sum(activity_count)) %>% 
  

knitr::kable()

agg_accel
```
Fridays tend to be a high activity day, while weekends seem to have lower activity. Saturdays especially have a lower activity count. Weeks 1, 2, and 5 seem to have a high activity count, with the exception of Saturday in Week 5. Week 4 seems to have a lower relative activity count as compared to other weeks of the same month. An activity count of 1440 is repeated twice - this number may have some significance.  



Single-panel plot
```{r single panel plot of accel_data}
accel_data %>%
  ggplot(aes(x = minute_of_day, y = activity_count)) +
  geom_line(aes(), alpha = .3) +
  labs(
    title = "Activity Plotted Over 5-Week Period",
    x = "Minute of Day",
    y = "Activity Count",
    caption = "data from accelerometer dataset"
  ) +
theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))

```


## Problem 3

Load and tidy data
```{r load and tidy nyc_noaa data}
library(p8105.datasets)
data("ny_noaa")

skimr::skim(ny_noaa)

```
This dataset from the National Oceanic and Atmospheric Association describes the weather in New York from all NY weather stations between January 1st, 1981 to December 31st, 2010. The data contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns. Variables include station ID, date of data collection, and measurements of precipitation, snow, snow depth, and maximum + minimum temperatures per day. There is significant missing data, especially as related to minimum and maximum temperatures - both tmin and tmax have over 1 million missing values.

